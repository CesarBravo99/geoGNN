{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-01-15T05:07:18.966877Z",
     "iopub.status.busy": "2024-01-15T05:07:18.966161Z",
     "iopub.status.idle": "2024-01-15T05:07:18.976355Z",
     "shell.execute_reply": "2024-01-15T05:07:18.974810Z",
     "shell.execute_reply.started": "2024-01-15T05:07:18.966825Z"
    },
    "id": "CRHi8vpymFci"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/notebooks')\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch_scatter\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "from src.basicGNN import basicGNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  MUTAG DATASET\n",
    "**Dataset Summary**\n",
    "\n",
    "The MUTAG dataset is a collection of nitroaromatic compounds and the goal is to predict their mutagenicity on Salmonella typhimurium'.\n",
    "\n",
    "\n",
    "**Supported Tasks and Leaderboards**\n",
    "\n",
    "MUTAG should be used for molecular property prediction (aiming to predict whether molecules have a mutagenic effect on a given bacterium or not), a binary classification task. The score used is accuracy, using a 10-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2024-01-15T05:07:19.776570Z",
     "iopub.status.busy": "2024-01-15T05:07:19.776095Z",
     "iopub.status.idle": "2024-01-15T05:07:19.786735Z",
     "shell.execute_reply": "2024-01-15T05:07:19.785143Z",
     "shell.execute_reply.started": "2024-01-15T05:07:19.776534Z"
    },
    "id": "unoZOcTqeFuI",
    "outputId": "31966846-ddf9-46e2-d561-8ff951556a7e"
   },
   "outputs": [],
   "source": [
    "dataset_directory = '/notebooks/data'\n",
    "dataset = TUDataset(root=dataset_directory, name='MUTAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:07:20.294057Z",
     "iopub.status.busy": "2024-01-15T05:07:20.292537Z",
     "iopub.status.idle": "2024-01-15T05:07:20.308756Z",
     "shell.execute_reply": "2024-01-15T05:07:20.307444Z",
     "shell.execute_reply.started": "2024-01-15T05:07:20.294009Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset: MUTAG(188):\n",
      "====================\n",
      "Number of graphs: 188\n",
      "Number of features: 7\n",
      "Number of classes: 2\n",
      "\n",
      "Data(edge_index=[2, 38], x=[17, 7], edge_attr=[38, 4], y=[1])\n",
      "=============================================================\n",
      "Number of nodes: 17\n",
      "Number of edges: 38\n",
      "Average node degree: 2.24\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: True\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "print(f'Dataset: {dataset}:')\n",
    "print('====================')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "data = dataset[0]  # Get the first graph object.\n",
    "\n",
    "print()\n",
    "print(data)\n",
    "print('=============================================================')\n",
    "\n",
    "# Gather some statistics about the first graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:07:20.996393Z",
     "iopub.status.busy": "2024-01-15T05:07:20.995824Z",
     "iopub.status.idle": "2024-01-15T05:07:21.009291Z",
     "shell.execute_reply": "2024-01-15T05:07:21.007860Z",
     "shell.execute_reply.started": "2024-01-15T05:07:20.996346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs: 150\n",
      "Number of test graphs: 38\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(12345)\n",
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:int(len(dataset)*0.8)]\n",
    "test_dataset = dataset[int(len(dataset)*0.8):]\n",
    "\n",
    "print(f'Number of training graphs: {len(train_dataset)}')\n",
    "print(f'Number of test graphs: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:07:21.625774Z",
     "iopub.status.busy": "2024-01-15T05:07:21.625220Z",
     "iopub.status.idle": "2024-01-15T05:07:21.633516Z",
     "shell.execute_reply": "2024-01-15T05:07:21.631972Z",
     "shell.execute_reply.started": "2024-01-15T05:07:21.625738Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:07:22.810110Z",
     "iopub.status.busy": "2024-01-15T05:07:22.809765Z",
     "iopub.status.idle": "2024-01-15T05:07:22.819873Z",
     "shell.execute_reply": "2024-01-15T05:07:22.818942Z",
     "shell.execute_reply.started": "2024-01-15T05:07:22.810084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "basicGNN(\n",
      "  (conv_layers): ModuleList(\n",
      "    (0): GraphConv(7, 64)\n",
      "    (1): GraphConv(64, 64)\n",
      "    (2): GraphConv(64, 64)\n",
      "  )\n",
      "  (final_layer): GraphConv(64, 2)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = basicGNN(dataset.num_node_features, [64, 64, 64], dataset.num_classes)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:09:24.525722Z",
     "iopub.status.busy": "2024-01-15T05:09:24.525266Z",
     "iopub.status.idle": "2024-01-15T05:09:32.560921Z",
     "shell.execute_reply": "2024-01-15T05:09:32.559713Z",
     "shell.execute_reply.started": "2024-01-15T05:09:24.525683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 002, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 003, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 004, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 005, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 006, Train Acc: 0.6467, Test Acc: 0.7368\n",
      "Epoch: 007, Train Acc: 0.6533, Test Acc: 0.7368\n",
      "Epoch: 008, Train Acc: 0.6533, Test Acc: 0.7368\n",
      "Epoch: 009, Train Acc: 0.7200, Test Acc: 0.8158\n",
      "Epoch: 010, Train Acc: 0.7333, Test Acc: 0.8158\n",
      "Epoch: 011, Train Acc: 0.7467, Test Acc: 0.8158\n",
      "Epoch: 012, Train Acc: 0.7533, Test Acc: 0.8158\n",
      "Epoch: 013, Train Acc: 0.7467, Test Acc: 0.8421\n",
      "Epoch: 014, Train Acc: 0.7867, Test Acc: 0.8421\n",
      "Epoch: 015, Train Acc: 0.7533, Test Acc: 0.7895\n",
      "Epoch: 016, Train Acc: 0.8133, Test Acc: 0.8421\n",
      "Epoch: 017, Train Acc: 0.8000, Test Acc: 0.8158\n",
      "Epoch: 018, Train Acc: 0.7933, Test Acc: 0.8158\n",
      "Epoch: 019, Train Acc: 0.7733, Test Acc: 0.7895\n",
      "Epoch: 020, Train Acc: 0.7867, Test Acc: 0.8158\n",
      "Epoch: 021, Train Acc: 0.7933, Test Acc: 0.7895\n",
      "Epoch: 022, Train Acc: 0.7933, Test Acc: 0.8158\n",
      "Epoch: 023, Train Acc: 0.8133, Test Acc: 0.8158\n",
      "Epoch: 024, Train Acc: 0.8000, Test Acc: 0.7368\n",
      "Epoch: 025, Train Acc: 0.8133, Test Acc: 0.8158\n",
      "Epoch: 026, Train Acc: 0.8067, Test Acc: 0.7368\n",
      "Epoch: 027, Train Acc: 0.8267, Test Acc: 0.8158\n",
      "Epoch: 028, Train Acc: 0.8333, Test Acc: 0.7895\n",
      "Epoch: 029, Train Acc: 0.8133, Test Acc: 0.8158\n",
      "Epoch: 030, Train Acc: 0.8333, Test Acc: 0.8158\n"
     ]
    }
   ],
   "source": [
    "model = basicGNN(in_channels=dataset.num_node_features, \n",
    "                 hidden_channels=[64, 64, 64],\n",
    "                 out_channels=dataset.num_classes, \n",
    "                 mlp=True, \n",
    "                 pooling=True)                 \n",
    "                 \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model):\n",
    "    losses = []\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        out = model(batch.x, batch.edge_index, batch.batch)\n",
    "        loss = criterion(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)  \n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        correct += int((pred == data.y).sum())  # Check against ground-truth labels.\n",
    "    return correct / len(loader.dataset)  # Derive ratio of correct predictions.\n",
    "\n",
    "\n",
    "for epoch in range(1, 31):\n",
    "    train(model)\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B5cDpOhEtdcS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "HxUtAD83iXXM",
    "uMVXEMXHmMcA",
    "6mMFB9HwmjQr",
    "FYxVK6Joot3b",
    "5qI94Tc3o0e3",
    "v1LbdCBEpM_j",
    "eYLIUNfHpW99"
   ],
   "name": "self_attn_pool.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
