{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a753136f-ed5c-4451-a651-add26c6eb417",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:23:39.788352Z",
     "iopub.status.busy": "2024-01-15T05:23:39.787891Z",
     "iopub.status.idle": "2024-01-15T05:23:44.437872Z",
     "shell.execute_reply": "2024-01-15T05:23:44.435842Z",
     "shell.execute_reply.started": "2024-01-15T05:23:39.788314Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.utils import negative_sampling\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d15f63c-f153-477c-9a95-1a2d06b0c0c0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:23:58.448685Z",
     "iopub.status.busy": "2024-01-15T05:23:58.448106Z",
     "iopub.status.idle": "2024-01-15T05:23:58.459245Z",
     "shell.execute_reply": "2024-01-15T05:23:58.458004Z",
     "shell.execute_reply.started": "2024-01-15T05:23:58.448649Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def encode(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        return self.conv2(x, edge_index)\n",
    "\n",
    "    def decode(self, z, edge_label_index):\n",
    "        return (z[edge_label_index[0]] * z[edge_label_index[1]]).sum(dim=-1)\n",
    "\n",
    "    def decode_all(self, z):\n",
    "        prob_adj = z @ z.t()\n",
    "        return (prob_adj > 0).nonzero(as_tuple=False).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77e8784e-c9bd-4db5-861c-42a285ffad81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:24:26.169107Z",
     "iopub.status.busy": "2024-01-15T05:24:26.168677Z",
     "iopub.status.idle": "2024-01-15T05:24:28.717703Z",
     "shell.execute_reply": "2024-01-15T05:24:28.715976Z",
     "shell.execute_reply.started": "2024-01-15T05:24:26.169078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Loss: 0.6930, Val: 0.6848, Test: 0.7024\n",
      "Epoch: 002, Loss: 0.6822, Val: 0.6717, Test: 0.6972\n",
      "Epoch: 003, Loss: 0.7112, Val: 0.6837, Test: 0.7036\n",
      "Epoch: 004, Loss: 0.6782, Val: 0.7147, Test: 0.7223\n",
      "Epoch: 005, Loss: 0.6855, Val: 0.7470, Test: 0.7503\n",
      "Epoch: 006, Loss: 0.6891, Val: 0.7717, Test: 0.7649\n",
      "Epoch: 007, Loss: 0.6901, Val: 0.7537, Test: 0.7450\n",
      "Epoch: 008, Loss: 0.6897, Val: 0.7288, Test: 0.7210\n",
      "Epoch: 009, Loss: 0.6882, Val: 0.7128, Test: 0.7068\n",
      "Epoch: 010, Loss: 0.6849, Val: 0.6986, Test: 0.6978\n",
      "Epoch: 011, Loss: 0.6802, Val: 0.6890, Test: 0.6927\n",
      "Epoch: 012, Loss: 0.6761, Val: 0.6815, Test: 0.6883\n",
      "Epoch: 013, Loss: 0.6781, Val: 0.6771, Test: 0.6841\n",
      "Epoch: 014, Loss: 0.6753, Val: 0.6737, Test: 0.6811\n",
      "Epoch: 015, Loss: 0.6682, Val: 0.6705, Test: 0.6800\n",
      "Epoch: 016, Loss: 0.6650, Val: 0.6713, Test: 0.6841\n",
      "Epoch: 017, Loss: 0.6616, Val: 0.6702, Test: 0.6897\n",
      "Epoch: 018, Loss: 0.6574, Val: 0.6669, Test: 0.6910\n",
      "Epoch: 019, Loss: 0.6486, Val: 0.6630, Test: 0.6896\n",
      "Epoch: 020, Loss: 0.6419, Val: 0.6668, Test: 0.6976\n",
      "Epoch: 021, Loss: 0.6382, Val: 0.6954, Test: 0.7306\n",
      "Epoch: 022, Loss: 0.6271, Val: 0.7498, Test: 0.7787\n",
      "Epoch: 023, Loss: 0.6154, Val: 0.7777, Test: 0.8015\n",
      "Epoch: 024, Loss: 0.6074, Val: 0.7801, Test: 0.8062\n",
      "Epoch: 025, Loss: 0.5932, Val: 0.7789, Test: 0.8060\n",
      "Epoch: 026, Loss: 0.5821, Val: 0.7807, Test: 0.8075\n",
      "Epoch: 027, Loss: 0.5714, Val: 0.7852, Test: 0.8134\n",
      "Epoch: 028, Loss: 0.5550, Val: 0.7866, Test: 0.8131\n",
      "Epoch: 029, Loss: 0.5504, Val: 0.7925, Test: 0.8169\n",
      "Epoch: 030, Loss: 0.5405, Val: 0.8022, Test: 0.8255\n",
      "Epoch: 031, Loss: 0.5416, Val: 0.8134, Test: 0.8348\n",
      "Epoch: 032, Loss: 0.5312, Val: 0.8294, Test: 0.8482\n",
      "Epoch: 033, Loss: 0.5165, Val: 0.8432, Test: 0.8575\n",
      "Epoch: 034, Loss: 0.5078, Val: 0.8554, Test: 0.8664\n",
      "Epoch: 035, Loss: 0.4993, Val: 0.8648, Test: 0.8738\n",
      "Epoch: 036, Loss: 0.4953, Val: 0.8669, Test: 0.8763\n",
      "Epoch: 037, Loss: 0.4911, Val: 0.8726, Test: 0.8781\n",
      "Epoch: 038, Loss: 0.4908, Val: 0.8773, Test: 0.8805\n",
      "Epoch: 039, Loss: 0.4817, Val: 0.8777, Test: 0.8845\n",
      "Epoch: 040, Loss: 0.4897, Val: 0.8780, Test: 0.8848\n",
      "Epoch: 041, Loss: 0.4819, Val: 0.8788, Test: 0.8852\n",
      "Epoch: 042, Loss: 0.4866, Val: 0.8806, Test: 0.8887\n",
      "Epoch: 043, Loss: 0.4738, Val: 0.8821, Test: 0.8913\n",
      "Epoch: 044, Loss: 0.4873, Val: 0.8844, Test: 0.8945\n",
      "Epoch: 045, Loss: 0.4791, Val: 0.8869, Test: 0.8967\n",
      "Epoch: 046, Loss: 0.4738, Val: 0.8883, Test: 0.8989\n",
      "Epoch: 047, Loss: 0.4764, Val: 0.8886, Test: 0.9001\n",
      "Epoch: 048, Loss: 0.4714, Val: 0.8928, Test: 0.9034\n",
      "Epoch: 049, Loss: 0.4726, Val: 0.8979, Test: 0.9052\n",
      "Epoch: 050, Loss: 0.4753, Val: 0.9001, Test: 0.9051\n",
      "Epoch: 051, Loss: 0.4723, Val: 0.8987, Test: 0.9051\n",
      "Epoch: 052, Loss: 0.4621, Val: 0.8948, Test: 0.9040\n",
      "Epoch: 053, Loss: 0.4634, Val: 0.8960, Test: 0.9046\n",
      "Epoch: 054, Loss: 0.4714, Val: 0.9008, Test: 0.9044\n",
      "Epoch: 055, Loss: 0.4650, Val: 0.9021, Test: 0.9042\n",
      "Epoch: 056, Loss: 0.4752, Val: 0.9010, Test: 0.9053\n",
      "Epoch: 057, Loss: 0.4658, Val: 0.8967, Test: 0.9068\n",
      "Epoch: 058, Loss: 0.4660, Val: 0.8987, Test: 0.9088\n",
      "Epoch: 059, Loss: 0.4683, Val: 0.9022, Test: 0.9095\n",
      "Epoch: 060, Loss: 0.4647, Val: 0.9046, Test: 0.9093\n",
      "Epoch: 061, Loss: 0.4595, Val: 0.9034, Test: 0.9094\n",
      "Epoch: 062, Loss: 0.4631, Val: 0.9010, Test: 0.9106\n",
      "Epoch: 063, Loss: 0.4593, Val: 0.9021, Test: 0.9127\n",
      "Epoch: 064, Loss: 0.4571, Val: 0.9039, Test: 0.9136\n",
      "Epoch: 065, Loss: 0.4562, Val: 0.9062, Test: 0.9130\n",
      "Epoch: 066, Loss: 0.4614, Val: 0.9062, Test: 0.9131\n",
      "Epoch: 067, Loss: 0.4619, Val: 0.9069, Test: 0.9148\n",
      "Epoch: 068, Loss: 0.4533, Val: 0.9081, Test: 0.9169\n",
      "Epoch: 069, Loss: 0.4606, Val: 0.9113, Test: 0.9181\n",
      "Epoch: 070, Loss: 0.4557, Val: 0.9120, Test: 0.9185\n",
      "Epoch: 071, Loss: 0.4561, Val: 0.9113, Test: 0.9175\n",
      "Epoch: 072, Loss: 0.4448, Val: 0.9120, Test: 0.9181\n",
      "Epoch: 073, Loss: 0.4497, Val: 0.9152, Test: 0.9194\n",
      "Epoch: 074, Loss: 0.4588, Val: 0.9156, Test: 0.9199\n",
      "Epoch: 075, Loss: 0.4566, Val: 0.9148, Test: 0.9201\n",
      "Epoch: 076, Loss: 0.4439, Val: 0.9132, Test: 0.9189\n",
      "Epoch: 077, Loss: 0.4522, Val: 0.9137, Test: 0.9187\n",
      "Epoch: 078, Loss: 0.4573, Val: 0.9162, Test: 0.9200\n",
      "Epoch: 079, Loss: 0.4461, Val: 0.9166, Test: 0.9210\n",
      "Epoch: 080, Loss: 0.4451, Val: 0.9161, Test: 0.9213\n",
      "Epoch: 081, Loss: 0.4497, Val: 0.9146, Test: 0.9200\n",
      "Epoch: 082, Loss: 0.4509, Val: 0.9139, Test: 0.9187\n",
      "Epoch: 083, Loss: 0.4471, Val: 0.9152, Test: 0.9191\n",
      "Epoch: 084, Loss: 0.4433, Val: 0.9171, Test: 0.9203\n",
      "Epoch: 085, Loss: 0.4463, Val: 0.9174, Test: 0.9205\n",
      "Epoch: 086, Loss: 0.4523, Val: 0.9169, Test: 0.9203\n",
      "Epoch: 087, Loss: 0.4483, Val: 0.9154, Test: 0.9187\n",
      "Epoch: 088, Loss: 0.4435, Val: 0.9168, Test: 0.9181\n",
      "Epoch: 089, Loss: 0.4445, Val: 0.9192, Test: 0.9195\n",
      "Epoch: 090, Loss: 0.4459, Val: 0.9214, Test: 0.9208\n",
      "Epoch: 091, Loss: 0.4436, Val: 0.9218, Test: 0.9212\n",
      "Epoch: 092, Loss: 0.4482, Val: 0.9222, Test: 0.9205\n",
      "Epoch: 093, Loss: 0.4422, Val: 0.9209, Test: 0.9185\n",
      "Epoch: 094, Loss: 0.4442, Val: 0.9225, Test: 0.9195\n",
      "Epoch: 095, Loss: 0.4371, Val: 0.9247, Test: 0.9218\n",
      "Epoch: 096, Loss: 0.4469, Val: 0.9249, Test: 0.9228\n",
      "Epoch: 097, Loss: 0.4406, Val: 0.9247, Test: 0.9229\n",
      "Epoch: 098, Loss: 0.4380, Val: 0.9252, Test: 0.9228\n",
      "Epoch: 099, Loss: 0.4347, Val: 0.9263, Test: 0.9227\n",
      "Epoch: 100, Loss: 0.4396, Val: 0.9259, Test: 0.9240\n",
      "Final Test: 0.9227\n"
     ]
    }
   ],
   "source": [
    "model = Net(dataset.num_features, 128, 64).to(device)\n",
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "\n",
    "    # We perform a new round of negative sampling for every training epoch:\n",
    "    neg_edge_index = negative_sampling(\n",
    "        edge_index=train_data.edge_index, num_nodes=train_data.num_nodes,\n",
    "        num_neg_samples=train_data.edge_label_index.size(1), method='sparse')\n",
    "\n",
    "    edge_label_index = torch.cat(\n",
    "        [train_data.edge_label_index, neg_edge_index],\n",
    "        dim=-1,\n",
    "    )\n",
    "    edge_label = torch.cat([\n",
    "        train_data.edge_label,\n",
    "        train_data.edge_label.new_zeros(neg_edge_index.size(1))\n",
    "    ], dim=0)\n",
    "\n",
    "    out = model.decode(z, edge_label_index).view(-1)\n",
    "    loss = criterion(out, edge_label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    z = model.encode(data.x, data.edge_index)\n",
    "    out = model.decode(z, data.edge_label_index).view(-1).sigmoid()\n",
    "    return roc_auc_score(data.edge_label.cpu().numpy(), out.cpu().numpy())\n",
    "\n",
    "\n",
    "best_val_auc = final_test_auc = 0\n",
    "for epoch in range(1, 101):\n",
    "    loss = train()\n",
    "    val_auc = test(val_data)\n",
    "    test_auc = test(test_data)\n",
    "    if val_auc > best_val_auc:\n",
    "        best_val_auc = val_auc\n",
    "        final_test_auc = test_auc\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Val: {val_auc:.4f}, '\n",
    "          f'Test: {test_auc:.4f}')\n",
    "\n",
    "print(f'Final Test: {final_test_auc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b937fc2-f3ed-4888-b9cf-24961dcc04da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-15T05:24:49.326729Z",
     "iopub.status.busy": "2024-01-15T05:24:49.326395Z",
     "iopub.status.idle": "2024-01-15T05:24:49.340783Z",
     "shell.execute_reply": "2024-01-15T05:24:49.339641Z",
     "shell.execute_reply.started": "2024-01-15T05:24:49.326702Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0,    0,  ..., 2707, 2707, 2707],\n",
       "        [   0,    2,    7,  ..., 2705, 2706, 2707]], device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = model.encode(test_data.x, test_data.edge_index)\n",
    "final_edge_index = model.decode_all(z)\n",
    "final_edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbbb002-8276-445a-8877-3b6dd8c5d62f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
