{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477f0dc-b04e-4ae2-bb57-9ffc3592544d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.datasets import md17\n",
    "from typing import Optional, List, Callable\n",
    "from torch_geometric.data import Data\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# preprocess work\n",
    "def collate(batch):\n",
    "    return Data(\n",
    "        pos = torch.cat([data.pos.unsqueeze(0) for data in batch], dim=0),\n",
    "        z = torch.cat([data.z.unsqueeze(0) for data in batch], dim=0),\n",
    "        energy = torch.cat([data.energy for data in batch], dim=0),\n",
    "        force = torch.cat([data.force.unsqueeze(0) for data in batch], dim=0),\n",
    "    )\n",
    "\n",
    "\n",
    "class my_MD17(md17.MD17):\n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str,\n",
    "        name: str,\n",
    "        train: Optional[bool] = None,\n",
    "        transform: Optional[Callable] = None,\n",
    "        pre_transform: Optional[Callable] = None,\n",
    "        pre_filter: Optional[Callable] = None,\n",
    "    ):\n",
    "        super().__init__(root, name, train, transform, pre_transform, pre_filter)\n",
    "        \n",
    "    @property\n",
    "    def processed_file_names(self) -> List[str]:\n",
    "        return ['data.pt']\n",
    "    \n",
    "    def process(self):\n",
    "        it = zip(self.raw_paths, self.processed_paths)\n",
    "        for raw_path, processed_path in it:\n",
    "            raw_data = np.load(raw_path)\n",
    "\n",
    "            if self.revised:\n",
    "                z = torch.from_numpy(raw_data['nuclear_charges']).long()\n",
    "                pos = torch.from_numpy(raw_data['coords']).float()\n",
    "                energy = torch.from_numpy(raw_data['energies']).float()\n",
    "                force = torch.from_numpy(raw_data['forces']).float()\n",
    "            else:\n",
    "                z = torch.from_numpy(raw_data['z']).long()\n",
    "                pos = torch.from_numpy(raw_data['R']).float()\n",
    "                energy = torch.from_numpy(raw_data['E']).float()\n",
    "                force = torch.from_numpy(raw_data['F']).float()\n",
    "\n",
    "            data_list = []\n",
    "            import tqdm\n",
    "            for i in tqdm.tqdm(range(pos.size(0))):\n",
    "                data = Data(z=z, pos=pos[i], energy=energy[i], force=force[i])\n",
    "                if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                    continue\n",
    "                if self.pre_transform is not None:\n",
    "                    data = self.pre_transform(data)\n",
    "                data_list.append(data)\n",
    "\n",
    "            torch.save(self.collate(data_list), processed_path)\n",
    "    \n",
    "    \n",
    "def md17_datawork(\n",
    "    root: str, \n",
    "    name: str,\n",
    "    batch_size: List[int],\n",
    "    **kwargs\n",
    "    ):\n",
    "    revised = 'revised' in name\n",
    "\n",
    "    data_point_num = [950, 50] if revised else [1000, 1000] \n",
    "    \n",
    "    # get dataset and collate function.\n",
    "    dataset = my_MD17(root=root, name=name)\n",
    "    # get meta data\n",
    "    global_y_mean = dataset.data.energy.mean()\n",
    "    global_y_std = dataset.data.energy.std()\n",
    "\n",
    "    # get basic configs\n",
    "    train_data_num, val_data_num = data_point_num\n",
    "    test_data_num = len(dataset) - train_data_num - val_data_num\n",
    "    train_batch_size, val_batch_size, test_batch_size = batch_size\n",
    "    \n",
    "    # random_split dataset\n",
    "    train_dataset, val_dataset, test_dataset = random_split(\n",
    "        dataset, \n",
    "        [train_data_num, \n",
    "        val_data_num, \n",
    "        test_data_num]\n",
    "        )\n",
    "    \n",
    "    \n",
    "    # get dataloaders\n",
    "    train_dataloader, val_dataloader, test_dataloader = (\n",
    "        DataLoader(train_dataset, num_workers=8, batch_size=train_batch_size, persistent_workers=True, shuffle=True, collate_fn=collate),\n",
    "        DataLoader(val_dataset, num_workers=4, batch_size=val_batch_size, persistent_workers=True, shuffle=False, collate_fn=collate),\n",
    "        DataLoader(test_dataset, num_workers=4, batch_size=test_batch_size, persistent_workers=True, shuffle=False, collate_fn=collate),\n",
    "    )\n",
    "    \n",
    "    return train_dataloader, val_dataloader, test_dataloader, global_y_mean, global_y_std\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
